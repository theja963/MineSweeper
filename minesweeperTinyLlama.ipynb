{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g1Lenw9xBI-h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "# from functools import reduce\n",
        "from scipy.ndimage import generic_filter\n",
        "\n",
        "\n",
        "class mineSweeper:\n",
        "    def __init__(self, position=[2,2], map_size=8, mines_ratio=1):\n",
        "        self.size = map_size\n",
        "        self.mines = round((mines_ratio/10)*(map_size**2))\n",
        "        self.generated_map = pd.DataFrame(np.full((self.size,self.size),0))\n",
        "        # self.counted_map = pd.DataFrame(np.full((self.size,self.size),0)) ##optimizing memory\n",
        "        self.revealed_map = pd.DataFrame(np.full((self.size,self.size),False))\n",
        "        self.flagged_map = pd.DataFrame(np.full((self.size,self.size),False)) ##optimizing memory failed\n",
        "        self.win_flag = False\n",
        "        self.terminate_flag = False\n",
        "        self.start_position = (((int(position[0]))*self.size)+((int(position[1])))) if len(position) else self.size**2/2\n",
        "\n",
        "         #incorporating first safe position\n",
        "\n",
        "\n",
        "    def generate_map(self):\n",
        "        random_numbers = random.sample(range(0,self.size**2),self.mines)\n",
        "        for i in random_numbers:\n",
        "            [col,row] = [i//self.size,i%self.size]\n",
        "            self.generated_map.iat[col,row]=\"M\"\n",
        "        self.generated_map = self.count_map(self.generated_map)\n",
        "\n",
        "    def check_window(self,values):\n",
        "        surround_count = int(np.count_nonzero(values)) if values[4]!=9 else 9\n",
        "        return surround_count\n",
        "\n",
        "    def count_map(self,check_map):\n",
        "        counted_map = generic_filter(check_map, self.check_window, size=(3,3), mode='constant', cval=0)\n",
        "        # for i in counted_map:\n",
        "        #     for j in i:\n",
        "        #         if j==9:\n",
        "        #             i=\"M\"\n",
        "        return pd.DataFrame(counted_map)\n",
        "\n",
        "class userAction(mineSweeper):\n",
        "\n",
        "    def generate_map(self): ## ensuring first forgiveness (may increase forgiveness values)\n",
        "        self.revealed_map = pd.DataFrame(np.full((self.size,self.size),False))\n",
        "        self.flagged_map = pd.DataFrame(np.full((self.size,self.size),False)) ##optimizing memory failed\n",
        "        self.win_flag = False\n",
        "        self.terminate_flag = False\n",
        "        i = self.start_position//self.size\n",
        "        j = self.start_position%self.size\n",
        "        safe_zone =[[x,y] for x in\n",
        "                        range(max(i-1, 0),min(i+2,self.size)) for y in\n",
        "                        range(max(j-1, 0),min(j+2,self.size))]\n",
        "\n",
        "        random_numbers = random.sample( [x for x in range(0,self.size**2)\n",
        "                                         if x != self.start_position],self.mines)\n",
        "        for i in random_numbers:\n",
        "            [col,row] = [i//self.size,i%self.size]\n",
        "            self.generated_map.iat[col,row]=9\n",
        "        self.generated_map = self.count_map(self.generated_map)\n",
        "        self.reveal_map([self.start_position//self.size,self.start_position%self.size])\n",
        "\n",
        "\n",
        "    def visible_map(self):\n",
        "        visible_map = self.generated_map.where(self.revealed_map)\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                if self.flagged_map.iat[i,j]:\n",
        "                    visible_map.iat[i,j] = \"F\"\n",
        "        return visible_map\n",
        "\n",
        "    def reveal_map(self,position):\n",
        "    #     [i,j] = position\n",
        "        i,j = int(position[0]),int(position[1])\n",
        "        # print (\"positions\", self.generated_map)\n",
        "        if self.revealed_map.iat[i,j] != \"F\":\n",
        "\n",
        "            self.revealed_map.iat[i,j] = True\n",
        "            # self.revealed_map.iat[i,j] = True\n",
        "            self.win_status()\n",
        "            if self.generated_map.iat[i,j] in [\"M\",9]:\n",
        "                print(\"Mines Triggered - Objective Failed\",self.visible_map())\n",
        "                self.terminate_flag = True\n",
        "                return -1.0 ##scores for training\n",
        "            elif self.generated_map.iat[i,j] == 0 and not self.revealed_map.iat[i,j]:\n",
        "                # self.revealed_map.iat[i,j] = True\n",
        "                surrounding_positions = [[x,y] for x in\n",
        "                        range(max(i-1, 0),min(i+2,self.size)) for y in\n",
        "                        range(max(j-1, 0),min(j+2,self.size))]\n",
        "                print(\"Surroundings safe, unlocking more area\",surrounding_positions)\n",
        "                for i in surrounding_positions:\n",
        "                    self.reveal_map(i)\n",
        "                #reduce(self.reveal_map(x),surrounding_positions)\n",
        "                return 0.05*len(surrounding_positions)\n",
        "            else:\n",
        "                print(\"Location revealed\",i,j)\n",
        "                return 0.01\n",
        "        else:\n",
        "            print(\"Location flagged\")\n",
        "            return -0.1\n",
        "\n",
        "    def flag_map(self,position):\n",
        "        [i,j] = position\n",
        "        print(\"Flagged location\",i,j)\n",
        "        if not self.flagged_map.iat[i,j]:\n",
        "            print(\"Already flagged\")\n",
        "            return -0.1\n",
        "        else:\n",
        "            if (self.flagged_map==True).sum().sum()<self.mines:\n",
        "                self.flagged_map.iat[i,j] = True\n",
        "                print(\"Flag consumed\")\n",
        "                return 0.1\n",
        "            elif (self.flagged_map==True).sum().sum()<self.mines:\n",
        "                print(\"Insufficient flags\")\n",
        "                return -0.1\n",
        "            else:\n",
        "                return self.win_status()\n",
        "\n",
        "    def unflag_map(self,position):\n",
        "        [i,j] = position\n",
        "        if self.flagged_map.iat[i,j]:\n",
        "            print(\"Unflagged\")\n",
        "            self.flagged_map.iat[i,j] = False\n",
        "        else:\n",
        "            print(\"No flag placed\")\n",
        "\n",
        "    def win_status(self):\n",
        "        if (self.revealed_map).sum().sum()+self.mines == self.size**2:\n",
        "            print(\"All mines marked\")\n",
        "            self.win_flag = True\n",
        "            self.terminate_flag=True\n",
        "            return 1.0\n",
        "        else:\n",
        "            print(\"Insufficient map revealed\")\n",
        "            return 0.0\n",
        "\n",
        "    ## traininic specifics required\n",
        "    def to_numpy_tensor(self):\n",
        "        revealed = self.revealed_map.to_numpy().astype(np.float32)\n",
        "        flagged = self.flagged_map.to_numpy().astype(np.float32)\n",
        "        board = self.generated_map.replace(\"M\", 9).fillna(0).to_numpy().astype(np.float32)\n",
        "        board_masked = board * revealed  # only show revealed numbers\n",
        "        return np.stack([board_masked, revealed, flagged], axis=0)  # shape: (3, size, size)\n",
        "\n",
        "    def training_action(self,action): ##wrapper to enable easier training\n",
        "        if action ==\"start\":\n",
        "            return(self.generate_map(),self.to_numpy_tensor(),self.terminate_flag,self.win_status())\n",
        "        a,x,y = action.split(\",\")\n",
        "        x= int(x)\n",
        "        y= int(y)\n",
        "        if a == \"f\":\n",
        "            return(self.flag_map([x,y]),self.to_numpy_tensor(),self.terminate_flag,self.win_status(),self.revealed_map)\n",
        "        elif a == \"u\":\n",
        "            return(self.unflag_map([x,y]),self.to_numpy_tensor(),self.terminate_flag,self.win_status(),self.revealed_map)\n",
        "        elif a == 'r':\n",
        "            return(self.reveal_map([x,y]),self.to_numpy_tensor(),self.terminate_flag,self.win_status(),self.revealed_map)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def llm_training_action(self,action):\n",
        "        while not self.terminate_flag:\n",
        "            response_provision = (self.stringify_visible_map,\"Please choose next action as \\nf:for flag, \\nu:for unflag, \\nr:for reveal followed by x,y coordinates\\n i.e. as action,x-coordinate,y-coordinate\")\n",
        "            try:\n",
        "                action,x,y = response_provision.split(\",\")\n",
        "                x= int(x)-1\n",
        "                y= int(y)-1\n",
        "                if action == \"f\":\n",
        "                    return(self.flag_map([x,y]),self.terminate_flag,self.win_status(),response_provision)\n",
        "                elif action == \"u\":\n",
        "                    return(self.unflag_map([x,y]),self.terminate_flag,self.win_status(),response_provision)\n",
        "                else:\n",
        "                    return(self.unflag_map([x,y]),self.terminate_flag,self.win_status(),response_provision)\n",
        "            except:\n",
        "                print(\"Please enter valid input\")\n",
        "            return response_provision\n",
        "        if execute_game_launcher.win_status() is True:\n",
        "            pass\n",
        "        restart = True if input(print(\"Would you like to restart? y/n\"))not in ['n','no', 'end-game'] else False\n",
        "\n",
        "    def stringify_visible_map(self):\n",
        "        visible = self.visible_map().to_numpy()\n",
        "        return \"\\\\n\".join([\" \".join(str(cell) if pd.notna(cell) else \"#\" for cell in row) for row in visible])\n",
        "\n",
        "\n",
        "def run_mcts(action:userAction):\n",
        "    # valid_actions = valid_actions*action.count_map(action.visible_map())\n",
        "    action_probs = action.count_map(action.visible_map().fillna(1))\n",
        "    valid_actions = [\n",
        "        action_probs.iat[i,j] if not action.revealed_map.iat[i, j] and not action.flagged_map.iat[i, j] and action_probs.iat[i,j] != 9 else 0.2*(not action.revealed_map.iat[i, j])\n",
        "        for i in range(action.size) for j in range(action.size)]\n",
        "\n",
        "    print(\"Action probables\",action_probs,\"before filter\",action.revealed_map,\"invisible\",action.generated_map)\n",
        "\n",
        "    valid_sum = sum([x for x in valid_actions])+1\n",
        "\n",
        "    if valid_sum==1: ## debug sequence for analysis\n",
        "        action.terminate_flag = True\n",
        "        action.win_status()\n",
        "        return None\n",
        "        # print(\"Action probables\",action_probs,\"before filter\",action.revealed_map,\"invisible\",action.generated_map)\n",
        "        # if input(print(\"Continue?\")): pass\n",
        "\n",
        "    print(\"Action bug\",valid_actions,valid_sum)\n",
        "    valid_actions = [x / valid_sum for x in valid_actions]\n",
        "    # print(\"Action probables\",valid_actions)\n",
        "    # action_probs = torch.tensor(valid_actions)\n",
        "\n",
        "    # print(\"Action probables\",action_probs,\"converted\")\n",
        "    value = valid_sum\n",
        "    return action_probs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "# from alphaZero import run_mcts\n",
        "# from minesweeperGenerator import userAction\n",
        "\n",
        "\n",
        "def load_tiny_llama_lora():\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\"TinyLLaMA/TinyLLaMA-1.1B-Chat\", device_map=\"auto\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"TinyLLaMA/TinyLLaMA-1.1B-Chat\")\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.CAUSAL_LM\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(base_model, lora_config)\n",
        "    return model, tokenizer\n",
        "\n",
        "llama_model, llama_tokenizer = load_tiny_llama_lora()\n",
        "\n",
        "def llama_agent_step(obs):\n",
        "    prompt = f\"You are playing Minesweeper. Board state:\\n{obs}\\nWhich cell should be uncovered next (return the index)?\"\n",
        "    inputs = llama_tokenizer(prompt, return_tensors=\"pt\").to(llama_model.device)\n",
        "    outputs = llama_model.generate(**inputs, max_new_tokens=10)\n",
        "    response = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    try:\n",
        "        action = int([s for s in response.split() if s.isdigit()][-1])\n",
        "    except:\n",
        "        action = np.random.randint(run_mcts(userAction))\n",
        "    return action\n",
        "\n",
        "game = userAction()\n",
        "game.training_action(\"start\")\n",
        "done = False\n",
        "while not done:\n",
        "    # obs = obs.stringify_visible_map()\n",
        "    action = llama_agent_step(obs)\n",
        "    reward, done, win, obs = game.llm_training_action(action)\n",
        "\n",
        "print(\"TinyLLaMA agent finished with reward:\", reward+win*10 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "id": "c4cZ-EZOBLKy",
        "outputId": "ab2987b7-2b65-45ab-a73b-d5a7d3e20e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "TinyLLaMA/TinyLLaMA-1.1B-Chat is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/TinyLLaMA/TinyLLaMA-1.1B-Chat/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1534\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1451\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    458\u001b[0m             )\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-686d103d-7bc21e875869f7b10dfb418d;d3b71eb9-e5fd-40e6-9048-3caef0218083)\n\nRepository Not Found for url: https://huggingface.co/TinyLLaMA/TinyLLaMA-1.1B-Chat/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-3501820649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mllama_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllama_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tiny_llama_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mllama_agent_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-3501820649.py\u001b[0m in \u001b[0;36mload_tiny_llama_lora\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_tiny_llama_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TinyLLaMA/TinyLLaMA-1.1B-Chat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TinyLLaMA/TinyLLaMA-1.1B-Chat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    509\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We cannot recover from them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGatedRepoError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: TinyLLaMA/TinyLLaMA-1.1B-Chat is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run TinyLLaMA inference in Google Colab without authentication\n",
        "!pip install llama-cpp-python\n",
        "!wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf -O tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\n",
        "\n",
        "from llama_cpp import Llama\n",
        "import numpy as np\n",
        "# from alphaZero import run_mcts\n",
        "# from minesweeperGenerator import userAction\n",
        "\n",
        "# Load TinyLLaMA GGUF model using llama.cpp\n",
        "llama_model = Llama(\n",
        "    model_path=\"tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\",  # Downloaded file\n",
        "    n_ctx=2048,\n",
        "    n_threads=4,\n",
        "    use_mlock=False  # Disabled in Colab\n",
        ")\n",
        "\n",
        "def llama_agent_step(obs):\n",
        "    prompt = f\"You are playing Minesweeper. Board state:\\n{obs}\\nWhich cell should be uncovered next (return the index)?\"\n",
        "    output = llama_model(\n",
        "        prompt,\n",
        "        max_tokens=16,\n",
        "        stop=[\"\\n\"],\n",
        "        echo=False\n",
        "    )\n",
        "    response = output[\"choices\"][0][\"text\"]\n",
        "    try:\n",
        "        action = int([s for s in response.split() if s.isdigit()][-1])\n",
        "    except:\n",
        "        action = np.random.randint(run_mcts(userAction))\n",
        "    return action\n",
        "\n",
        "# Initialize the Minesweeper environment\n",
        "game = userAction()\n",
        "game.training_action(\"start\")\n",
        "done = False\n",
        "\n",
        "# Main gameplay loop\n",
        "while not done:\n",
        "    visible_map = game.stringify_visible_map()\n",
        "    action = llama_agent_step(visible_map)\n",
        "    reward, done, win, visible_map = game.llm_training_action(action)\n",
        "\n",
        "print(\"TinyLLaMA agent finished with reward:\", reward + win * 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GClqWPVJI3sa",
        "outputId": "a2574785-2f92-4993-81c0-1558fc938340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Using cached llama_cpp_python-0.3.12.tar.gz (49.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n"
          ]
        }
      ]
    }
  ]
}